{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping experiment setting to variance and std on early node\n",
    "mapping = {\n",
    "            'cogsci_learning': [-8, -4, 4, 8],\n",
    "            'mini_variance'  : [-2, -1, 1, 2],\n",
    "            'zero_variance'  : [1, 1, 1, 1],\n",
    "            'large_variance' : [-48, -24, 24, 48],\n",
    "            'high_increasing': [-4, -2, 2, 4]\n",
    "                          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "considered_experiment_settings = [\"high_increasing\", \"large_variance\", \"cogsci_learning\", \"mini_variance\", \"zero_variance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.DataFrame()\n",
    "for experiment_setting in considered_experiment_settings:\n",
    "    data_in = pd.read_csv(f\"data/processed/simulated/{experiment_setting}/MCL/linear_depth/search_space/1729_depth_only_baseline_null.csv\")\n",
    "    data_in['experiment_setting']= experiment_setting\n",
    "    data = pd.concat([data, data_in])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>w</th>\n",
       "      <th>taken_paths</th>\n",
       "      <th>costs</th>\n",
       "      <th>loss</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>trial_id</th>\n",
       "      <th>i_episode</th>\n",
       "      <th>actions</th>\n",
       "      <th>...</th>\n",
       "      <th>depth_cost_weight</th>\n",
       "      <th>pid</th>\n",
       "      <th>num_early</th>\n",
       "      <th>num_middle</th>\n",
       "      <th>num_late</th>\n",
       "      <th>num_clicks</th>\n",
       "      <th>unbounded_present_bias</th>\n",
       "      <th>unbounded_loss</th>\n",
       "      <th>state</th>\n",
       "      <th>experiment_setting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[54.0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.0, -2.0, 8.0, 48.0, -24.0, 2.0, -4.0, -48.0...</td>\n",
       "      <td>3827219843471436276</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0, Cat, Cat, Cat, Cat, Cat, Cat, Cat, Cat, Ca...</td>\n",
       "      <td>high_increasing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 15.5454392236338, 48.857094702...</td>\n",
       "      <td>[5, 6, 8]</td>\n",
       "      <td>[-1.0, -1.0, -1.0, 20.0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.0, -2.0, -4.0, -24.0, -48.0, 4.0, -8.0, 24....</td>\n",
       "      <td>-4289689371375290671</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>(0, Cat, Cat, Cat, Cat, Cat, Cat, Cat, Cat, Ca...</td>\n",
       "      <td>high_increasing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 15.5454392236338, 48.857094702...</td>\n",
       "      <td>[5, 6, 8]</td>\n",
       "      <td>[-1.0, -1.0, -1.0, 20.0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.0, -2.0, -4.0, -24.0, -48.0, 4.0, -8.0, 24....</td>\n",
       "      <td>-4289689371375290671</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>(0, Cat, Cat, Cat, Cat, Cat, Cat, Cat, Cat, -4...</td>\n",
       "      <td>high_increasing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 15.5454392236338, 48.857094702...</td>\n",
       "      <td>[5, 6, 8]</td>\n",
       "      <td>[-1.0, -1.0, -1.0, 20.0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.0, -2.0, -4.0, -24.0, -48.0, 4.0, -8.0, 24....</td>\n",
       "      <td>-4289689371375290671</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>(0, -2.0, Cat, Cat, Cat, Cat, Cat, Cat, Cat, -...</td>\n",
       "      <td>high_increasing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 15.5454392236338, 48.857094702...</td>\n",
       "      <td>[5, 6, 8]</td>\n",
       "      <td>[-1.0, -1.0, -1.0, 20.0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.0, -2.0, -4.0, -24.0, -48.0, 4.0, -8.0, 24....</td>\n",
       "      <td>-4289689371375290671</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>(0, -2.0, Cat, Cat, Cat, 4.0, Cat, Cat, Cat, -...</td>\n",
       "      <td>high_increasing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  \\\n",
       "0           0             0   \n",
       "1           1             1   \n",
       "2           2             1   \n",
       "3           3             1   \n",
       "4           4             1   \n",
       "\n",
       "                                                   w taken_paths  \\\n",
       "0                                    [0, 0, 0, 0, 0]   [1, 2, 3]   \n",
       "1  [0.0, 0.0, 0.0, 15.5454392236338, 48.857094702...   [5, 6, 8]   \n",
       "2  [0.0, 0.0, 0.0, 15.5454392236338, 48.857094702...   [5, 6, 8]   \n",
       "3  [0.0, 0.0, 0.0, 15.5454392236338, 48.857094702...   [5, 6, 8]   \n",
       "4  [0.0, 0.0, 0.0, 15.5454392236338, 48.857094702...   [5, 6, 8]   \n",
       "\n",
       "                      costs  loss  \\\n",
       "0                    [54.0]   NaN   \n",
       "1  [-1.0, -1.0, -1.0, 20.0]   NaN   \n",
       "2  [-1.0, -1.0, -1.0, 20.0]   NaN   \n",
       "3  [-1.0, -1.0, -1.0, 20.0]   NaN   \n",
       "4  [-1.0, -1.0, -1.0, 20.0]   NaN   \n",
       "\n",
       "                                        ground_truth             trial_id  \\\n",
       "0  [0.0, -2.0, 8.0, 48.0, -24.0, 2.0, -4.0, -48.0...  3827219843471436276   \n",
       "1  [0.0, -2.0, -4.0, -24.0, -48.0, 4.0, -8.0, 24.... -4289689371375290671   \n",
       "2  [0.0, -2.0, -4.0, -24.0, -48.0, 4.0, -8.0, 24.... -4289689371375290671   \n",
       "3  [0.0, -2.0, -4.0, -24.0, -48.0, 4.0, -8.0, 24.... -4289689371375290671   \n",
       "4  [0.0, -2.0, -4.0, -24.0, -48.0, 4.0, -8.0, 24.... -4289689371375290671   \n",
       "\n",
       "   i_episode  actions  ...  depth_cost_weight pid num_early  num_middle  \\\n",
       "0          0        0  ...                2.5   0     False       False   \n",
       "1          1        9  ...                2.5   0      True       False   \n",
       "2          1        1  ...                2.5   0      True       False   \n",
       "3          1        5  ...                2.5   0      True       False   \n",
       "4          1        0  ...                2.5   0     False       False   \n",
       "\n",
       "  num_late num_clicks unbounded_present_bias unbounded_loss  \\\n",
       "0    False      False                    0.0            0.0   \n",
       "1    False       True                    8.0          -28.0   \n",
       "2    False       True                    8.0          -28.0   \n",
       "3    False       True                    8.0          -28.0   \n",
       "4    False      False                    8.0          -28.0   \n",
       "\n",
       "                                               state  experiment_setting  \n",
       "0  (0, Cat, Cat, Cat, Cat, Cat, Cat, Cat, Cat, Ca...     high_increasing  \n",
       "1  (0, Cat, Cat, Cat, Cat, Cat, Cat, Cat, Cat, Ca...     high_increasing  \n",
       "2  (0, Cat, Cat, Cat, Cat, Cat, Cat, Cat, Cat, -4...     high_increasing  \n",
       "3  (0, -2.0, Cat, Cat, Cat, Cat, Cat, Cat, Cat, -...     high_increasing  \n",
       "4  (0, -2.0, Cat, Cat, Cat, 4.0, Cat, Cat, Cat, -...     high_increasing  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column with variance and std of the experiment settings\n",
    "data[\"std_early_nodes\"] = data[\"experiment_setting\"].apply(lambda experiment_setting: np.std(mapping[experiment_setting]))\n",
    "data[\"variance_early_nodes\"] = data[\"experiment_setting\"].apply(lambda experiment_setting: np.var(mapping[experiment_setting]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## normalization\n",
    "# variance\n",
    "data[\"norm_variance_early_nodes\"] = (\n",
    "                                    (data[\"variance_early_nodes\"]-data[\"variance_early_nodes\"].min())/\n",
    "                                    (data[\"variance_early_nodes\"].max()-data[\"variance_early_nodes\"].min()))\n",
    "# std\n",
    "data[\"norm_std_early_nodes\"]      = (\n",
    "                                    (data[\"std_early_nodes\"]-data[\"std_early_nodes\"].min())/\n",
    "                                    (data[\"std_early_nodes\"].max()-data[\"std_early_nodes\"].min()))\n",
    "# data[\"norm_std_early_nodes\"] = preprocessing.Normalizer(data[\"std_early_nodes\"])\n",
    "# data[\"norm_variance_early_nodes\"] = preprocessing.Normalizer(data[\"variance_early_nodes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group data by factors\n",
    "grouped_data = data.groupby([\"pid\", \"i_episode\", \"sim_cost_parameter_values\", \"sim_experiment_setting\"], as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>num_early</td>    <th>  R-squared:         </th>  <td>   0.005</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.005</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   5183.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 19 Dec 2022</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:52:32</td>     <th>  Log-Likelihood:    </th> <td>-5.2421e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>3400000</td>     <th>  AIC:               </th>  <td>1.048e+07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>3399996</td>     <th>  BIC:               </th>  <td>1.048e+07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                  <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                   <td>    0.7834</td> <td>    0.001</td> <td>  643.347</td> <td> 0.000</td> <td>    0.781</td> <td>    0.786</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>i_episode</th>                   <td>   -0.0015</td> <td> 2.13e-05</td> <td>  -68.849</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>i_episode:depth_cost_weight</th> <td>-2.859e-05</td> <td> 1.85e-06</td> <td>  -15.440</td> <td> 0.000</td> <td>-3.22e-05</td> <td> -2.5e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>depth_cost_weight</th>           <td>   -0.0043</td> <td>    0.000</td> <td>  -40.353</td> <td> 0.000</td> <td>   -0.004</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>559576.601</td> <th>  Durbin-Watson:     </th>  <td>   1.946</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>895813.867</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td> 1.257</td>   <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>        <td> 2.939</td>   <th>  Cond. No.          </th>  <td>1.29e+03</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.29e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              num_early   R-squared:                       0.005\n",
       "Model:                            OLS   Adj. R-squared:                  0.005\n",
       "Method:                 Least Squares   F-statistic:                     5183.\n",
       "Date:                Mon, 19 Dec 2022   Prob (F-statistic):               0.00\n",
       "Time:                        10:52:32   Log-Likelihood:            -5.2421e+06\n",
       "No. Observations:             3400000   AIC:                         1.048e+07\n",
       "Df Residuals:                 3399996   BIC:                         1.048e+07\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================================\n",
       "                                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------\n",
       "Intercept                       0.7834      0.001    643.347      0.000       0.781       0.786\n",
       "i_episode                      -0.0015   2.13e-05    -68.849      0.000      -0.002      -0.001\n",
       "i_episode:depth_cost_weight -2.859e-05   1.85e-06    -15.440      0.000   -3.22e-05    -2.5e-05\n",
       "depth_cost_weight              -0.0043      0.000    -40.353      0.000      -0.004      -0.004\n",
       "==============================================================================\n",
       "Omnibus:                   559576.601   Durbin-Watson:                   1.946\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           895813.867\n",
       "Skew:                           1.257   Prob(JB):                         0.00\n",
       "Kurtosis:                       2.939   Cond. No.                     1.29e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.29e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula = \"num_early ~ i_episode + i_episode:depth_cost_weight + depth_cost_weight + 1\"\n",
    "res = smf.ols(formula=formula, data=grouped_data).fit(\n",
    "                    missing=\"drop\"\n",
    "                )\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>num_early</td>    <th>  R-squared:         </th>  <td>   0.056</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.056</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>1.063e+04</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 19 Dec 2022</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:53:00</td>     <th>  Log-Likelihood:    </th> <td>-5.1518e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>3400000</td>     <th>  AIC:               </th>  <td>1.030e+07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>3399980</td>     <th>  BIC:               </th>  <td>1.030e+07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    19</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                                    <td></td>                                       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                                             <td>    0.7766</td> <td>    0.003</td> <td>  292.018</td> <td> 0.000</td> <td>    0.771</td> <td>    0.782</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sim_experiment_setting[T.high_increasing]</th>                             <td>   -0.0534</td> <td>    0.004</td> <td>  -14.228</td> <td> 0.000</td> <td>   -0.061</td> <td>   -0.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sim_experiment_setting[T.large_variance]</th>                              <td>    0.2851</td> <td>    0.004</td> <td>   75.876</td> <td> 0.000</td> <td>    0.278</td> <td>    0.292</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sim_experiment_setting[T.mini_variance]</th>                               <td>   -0.0845</td> <td>    0.004</td> <td>  -22.515</td> <td> 0.000</td> <td>   -0.092</td> <td>   -0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sim_experiment_setting[T.zero_variance]</th>                               <td>   -0.1292</td> <td>    0.004</td> <td>  -34.385</td> <td> 0.000</td> <td>   -0.137</td> <td>   -0.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>i_episode</th>                                                             <td>   -0.0024</td> <td> 4.65e-05</td> <td>  -51.373</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sim_experiment_setting[T.high_increasing]:i_episode</th>                   <td>   -0.0005</td> <td> 6.56e-05</td> <td>   -8.025</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sim_experiment_setting[T.large_variance]:i_episode</th>                    <td>    0.0050</td> <td> 6.57e-05</td> <td>   76.660</td> <td> 0.000</td> <td>    0.005</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sim_experiment_setting[T.mini_variance]:i_episode</th>                     <td> 4.513e-06</td> <td> 6.56e-05</td> <td>    0.069</td> <td> 0.945</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sim_experiment_setting[T.zero_variance]:i_episode</th>                     <td>    0.0003</td> <td> 6.56e-05</td> <td>    5.051</td> <td> 0.000</td> <td>    0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>i_episode:depth_cost_weight</th>                                           <td>  3.22e-06</td> <td> 3.73e-06</td> <td>    0.863</td> <td> 0.388</td> <td>-4.09e-06</td> <td> 1.05e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sim_experiment_setting[T.high_increasing]:i_episode:depth_cost_weight</th> <td>   -0.0001</td> <td> 5.89e-06</td> <td>  -20.132</td> <td> 0.000</td> <td>   -0.000</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sim_experiment_setting[T.large_variance]:i_episode:depth_cost_weight</th>  <td> 7.563e-05</td> <td> 5.01e-06</td> <td>   15.086</td> <td> 0.000</td> <td> 6.58e-05</td> <td> 8.55e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sim_experiment_setting[T.mini_variance]:i_episode:depth_cost_weight</th>   <td>   -0.0001</td> <td> 5.75e-06</td> <td>  -17.462</td> <td> 0.000</td> <td>   -0.000</td> <td>-8.91e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sim_experiment_setting[T.zero_variance]:i_episode:depth_cost_weight</th>   <td>   -0.0001</td> <td>    6e-06</td> <td>  -17.490</td> <td> 0.000</td> <td>   -0.000</td> <td>-9.32e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>depth_cost_weight</th>                                                     <td>   -0.0103</td> <td>    0.000</td> <td>  -48.524</td> <td> 0.000</td> <td>   -0.011</td> <td>   -0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sim_experiment_setting[T.high_increasing]:depth_cost_weight</th>           <td>    0.0057</td> <td>    0.000</td> <td>   17.118</td> <td> 0.000</td> <td>    0.005</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sim_experiment_setting[T.large_variance]:depth_cost_weight</th>            <td>    0.0041</td> <td>    0.000</td> <td>   14.335</td> <td> 0.000</td> <td>    0.004</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sim_experiment_setting[T.mini_variance]:depth_cost_weight</th>             <td>    0.0082</td> <td>    0.000</td> <td>   25.281</td> <td> 0.000</td> <td>    0.008</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sim_experiment_setting[T.zero_variance]:depth_cost_weight</th>             <td>    0.0210</td> <td>    0.000</td> <td>   60.992</td> <td> 0.000</td> <td>    0.020</td> <td>    0.022</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>562601.603</td> <th>  Durbin-Watson:     </th>  <td>   1.916</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>898401.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td> 1.255</td>   <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>        <td> 3.199</td>   <th>  Cond. No.          </th>  <td>7.58e+03</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 7.58e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              num_early   R-squared:                       0.056\n",
       "Model:                            OLS   Adj. R-squared:                  0.056\n",
       "Method:                 Least Squares   F-statistic:                 1.063e+04\n",
       "Date:                Mon, 19 Dec 2022   Prob (F-statistic):               0.00\n",
       "Time:                        10:53:00   Log-Likelihood:            -5.1518e+06\n",
       "No. Observations:             3400000   AIC:                         1.030e+07\n",
       "Df Residuals:                 3399980   BIC:                         1.030e+07\n",
       "Df Model:                          19                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=========================================================================================================================================\n",
       "                                                                            coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                                                 0.7766      0.003    292.018      0.000       0.771       0.782\n",
       "sim_experiment_setting[T.high_increasing]                                -0.0534      0.004    -14.228      0.000      -0.061      -0.046\n",
       "sim_experiment_setting[T.large_variance]                                  0.2851      0.004     75.876      0.000       0.278       0.292\n",
       "sim_experiment_setting[T.mini_variance]                                  -0.0845      0.004    -22.515      0.000      -0.092      -0.077\n",
       "sim_experiment_setting[T.zero_variance]                                  -0.1292      0.004    -34.385      0.000      -0.137      -0.122\n",
       "i_episode                                                                -0.0024   4.65e-05    -51.373      0.000      -0.002      -0.002\n",
       "sim_experiment_setting[T.high_increasing]:i_episode                      -0.0005   6.56e-05     -8.025      0.000      -0.001      -0.000\n",
       "sim_experiment_setting[T.large_variance]:i_episode                        0.0050   6.57e-05     76.660      0.000       0.005       0.005\n",
       "sim_experiment_setting[T.mini_variance]:i_episode                      4.513e-06   6.56e-05      0.069      0.945      -0.000       0.000\n",
       "sim_experiment_setting[T.zero_variance]:i_episode                         0.0003   6.56e-05      5.051      0.000       0.000       0.000\n",
       "i_episode:depth_cost_weight                                             3.22e-06   3.73e-06      0.863      0.388   -4.09e-06    1.05e-05\n",
       "sim_experiment_setting[T.high_increasing]:i_episode:depth_cost_weight    -0.0001   5.89e-06    -20.132      0.000      -0.000      -0.000\n",
       "sim_experiment_setting[T.large_variance]:i_episode:depth_cost_weight   7.563e-05   5.01e-06     15.086      0.000    6.58e-05    8.55e-05\n",
       "sim_experiment_setting[T.mini_variance]:i_episode:depth_cost_weight      -0.0001   5.75e-06    -17.462      0.000      -0.000   -8.91e-05\n",
       "sim_experiment_setting[T.zero_variance]:i_episode:depth_cost_weight      -0.0001      6e-06    -17.490      0.000      -0.000   -9.32e-05\n",
       "depth_cost_weight                                                        -0.0103      0.000    -48.524      0.000      -0.011      -0.010\n",
       "sim_experiment_setting[T.high_increasing]:depth_cost_weight               0.0057      0.000     17.118      0.000       0.005       0.006\n",
       "sim_experiment_setting[T.large_variance]:depth_cost_weight                0.0041      0.000     14.335      0.000       0.004       0.005\n",
       "sim_experiment_setting[T.mini_variance]:depth_cost_weight                 0.0082      0.000     25.281      0.000       0.008       0.009\n",
       "sim_experiment_setting[T.zero_variance]:depth_cost_weight                 0.0210      0.000     60.992      0.000       0.020       0.022\n",
       "==============================================================================\n",
       "Omnibus:                   562601.603   Durbin-Watson:                   1.916\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           898401.102\n",
       "Skew:                           1.255   Prob(JB):                         0.00\n",
       "Kurtosis:                       3.199   Cond. No.                     7.58e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 7.58e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# early_node_variance ~ experiment_setting\n",
    "formula = \"num_early ~ i_episode + i_episode:depth_cost_weight + depth_cost_weight + sim_experiment_setting + sim_experiment_setting:i_episode + sim_experiment_setting:i_episode:depth_cost_weight + sim_experiment_setting:depth_cost_weight + 1\"\n",
    "res = smf.ols(formula=formula, data=grouped_data).fit(\n",
    "                    missing=\"drop\"\n",
    "                )\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>num_early</td>    <th>  R-squared:         </th>  <td>   0.119</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.119</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>6.565e+04</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 19 Dec 2022</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:53:09</td>     <th>  Log-Likelihood:    </th> <td>-5.0344e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>3400000</td>     <th>  AIC:               </th>  <td>1.007e+07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>3399992</td>     <th>  BIC:               </th>  <td>1.007e+07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                            <td></td>                               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                             <td>    0.6485</td> <td>    0.001</td> <td>  525.696</td> <td> 0.000</td> <td>    0.646</td> <td>    0.651</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>i_episode</th>                                             <td>   -0.0019</td> <td> 2.16e-05</td> <td>  -88.906</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>i_episode:depth_cost_weight</th>                           <td>-4.081e-05</td> <td> 2.03e-06</td> <td>  -20.108</td> <td> 0.000</td> <td>-4.48e-05</td> <td>-3.68e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>depth_cost_weight</th>                                     <td>   -0.0015</td> <td>    0.000</td> <td>  -12.816</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>norm_variance_early_nodes</th>                             <td>    0.1581</td> <td>    0.001</td> <td>  294.696</td> <td> 0.000</td> <td>    0.157</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>norm_variance_early_nodes:i_episode</th>                   <td>    0.0004</td> <td> 9.37e-06</td> <td>   40.127</td> <td> 0.000</td> <td>    0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>norm_variance_early_nodes:i_episode:depth_cost_weight</th> <td> 1.916e-05</td> <td>  4.3e-07</td> <td>   44.563</td> <td> 0.000</td> <td> 1.83e-05</td> <td>    2e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>norm_variance_early_nodes:depth_cost_weight</th>           <td>    0.0004</td> <td> 2.35e-05</td> <td>   17.179</td> <td> 0.000</td> <td>    0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>619902.746</td> <th>  Durbin-Watson:     </th>  <td>   1.929</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>1018112.631</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td> 1.308</td>   <th>  Prob(JB):          </th>  <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>        <td> 3.583</td>   <th>  Cond. No.          </th>  <td>6.77e+03</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 6.77e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              num_early   R-squared:                       0.119\n",
       "Model:                            OLS   Adj. R-squared:                  0.119\n",
       "Method:                 Least Squares   F-statistic:                 6.565e+04\n",
       "Date:                Mon, 19 Dec 2022   Prob (F-statistic):               0.00\n",
       "Time:                        10:53:09   Log-Likelihood:            -5.0344e+06\n",
       "No. Observations:             3400000   AIC:                         1.007e+07\n",
       "Df Residuals:                 3399992   BIC:                         1.007e+07\n",
       "Df Model:                           7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=========================================================================================================================\n",
       "                                                            coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                                 0.6485      0.001    525.696      0.000       0.646       0.651\n",
       "i_episode                                                -0.0019   2.16e-05    -88.906      0.000      -0.002      -0.002\n",
       "i_episode:depth_cost_weight                           -4.081e-05   2.03e-06    -20.108      0.000   -4.48e-05   -3.68e-05\n",
       "depth_cost_weight                                        -0.0015      0.000    -12.816      0.000      -0.002      -0.001\n",
       "norm_variance_early_nodes                                 0.1581      0.001    294.696      0.000       0.157       0.159\n",
       "norm_variance_early_nodes:i_episode                       0.0004   9.37e-06     40.127      0.000       0.000       0.000\n",
       "norm_variance_early_nodes:i_episode:depth_cost_weight  1.916e-05    4.3e-07     44.563      0.000    1.83e-05       2e-05\n",
       "norm_variance_early_nodes:depth_cost_weight               0.0004   2.35e-05     17.179      0.000       0.000       0.000\n",
       "==============================================================================\n",
       "Omnibus:                   619902.746   Durbin-Watson:                   1.929\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1018112.631\n",
       "Skew:                           1.308   Prob(JB):                         0.00\n",
       "Kurtosis:                       3.583   Cond. No.                     6.77e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 6.77e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# early_node_variance ~ norm_variance_early_nodes\n",
    "formula = \"num_early ~ i_episode + i_episode:depth_cost_weight + depth_cost_weight + norm_variance_early_nodes + norm_variance_early_nodes:i_episode + norm_variance_early_nodes:i_episode:depth_cost_weight + norm_variance_early_nodes:depth_cost_weight + 1\"\n",
    "res = smf.ols(formula=formula, data=grouped_data).fit(\n",
    "                    missing=\"drop\"\n",
    "                )\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>num_early</td>    <th>  R-squared:         </th>  <td>   0.152</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.152</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>8.684e+04</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 19 Dec 2022</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:53:38</td>     <th>  Log-Likelihood:    </th> <td>-4.9703e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>3400000</td>     <th>  AIC:               </th>  <td>9.941e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>3399992</td>     <th>  BIC:               </th>  <td>9.941e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                          <td></td>                            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                        <td>    0.5810</td> <td>    0.001</td> <td>  461.654</td> <td> 0.000</td> <td>    0.579</td> <td>    0.583</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>i_episode</th>                                        <td>   -0.0019</td> <td> 2.21e-05</td> <td>  -87.072</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>i_episode:depth_cost_weight</th>                      <td>-4.242e-05</td> <td> 2.11e-06</td> <td>  -20.117</td> <td> 0.000</td> <td>-4.66e-05</td> <td>-3.83e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>depth_cost_weight</th>                                <td>    0.0004</td> <td>    0.000</td> <td>    3.634</td> <td> 0.000</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>norm_std_early_nodes</th>                             <td>    0.1918</td> <td>    0.001</td> <td>  356.089</td> <td> 0.000</td> <td>    0.191</td> <td>    0.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>norm_std_early_nodes:i_episode</th>                   <td>    0.0003</td> <td> 9.42e-06</td> <td>   28.334</td> <td> 0.000</td> <td>    0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>norm_std_early_nodes:i_episode:depth_cost_weight</th> <td> 1.892e-05</td> <td>  4.4e-07</td> <td>   42.959</td> <td> 0.000</td> <td> 1.81e-05</td> <td> 1.98e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>norm_std_early_nodes:depth_cost_weight</th>           <td>    0.0003</td> <td>  2.4e-05</td> <td>   12.879</td> <td> 0.000</td> <td>    0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>605881.398</td> <th>  Durbin-Watson:     </th>  <td>   1.938</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>983329.869</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td> 1.277</td>   <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>        <td> 3.647</td>   <th>  Cond. No.          </th>  <td>7.17e+03</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 7.17e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              num_early   R-squared:                       0.152\n",
       "Model:                            OLS   Adj. R-squared:                  0.152\n",
       "Method:                 Least Squares   F-statistic:                 8.684e+04\n",
       "Date:                Mon, 19 Dec 2022   Prob (F-statistic):               0.00\n",
       "Time:                        10:53:38   Log-Likelihood:            -4.9703e+06\n",
       "No. Observations:             3400000   AIC:                         9.941e+06\n",
       "Df Residuals:                 3399992   BIC:                         9.941e+06\n",
       "Df Model:                           7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================================================\n",
       "                                                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                            0.5810      0.001    461.654      0.000       0.579       0.583\n",
       "i_episode                                           -0.0019   2.21e-05    -87.072      0.000      -0.002      -0.002\n",
       "i_episode:depth_cost_weight                      -4.242e-05   2.11e-06    -20.117      0.000   -4.66e-05   -3.83e-05\n",
       "depth_cost_weight                                    0.0004      0.000      3.634      0.000       0.000       0.001\n",
       "norm_std_early_nodes                                 0.1918      0.001    356.089      0.000       0.191       0.193\n",
       "norm_std_early_nodes:i_episode                       0.0003   9.42e-06     28.334      0.000       0.000       0.000\n",
       "norm_std_early_nodes:i_episode:depth_cost_weight  1.892e-05    4.4e-07     42.959      0.000    1.81e-05    1.98e-05\n",
       "norm_std_early_nodes:depth_cost_weight               0.0003    2.4e-05     12.879      0.000       0.000       0.000\n",
       "==============================================================================\n",
       "Omnibus:                   605881.398   Durbin-Watson:                   1.938\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           983329.869\n",
       "Skew:                           1.277   Prob(JB):                         0.00\n",
       "Kurtosis:                       3.647   Cond. No.                     7.17e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 7.17e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# early_node_variance ~ norm_std_early_nodes\n",
    "formula = \"num_early ~ i_episode + i_episode:depth_cost_weight + depth_cost_weight + norm_std_early_nodes + norm_std_early_nodes:i_episode + norm_std_early_nodes:i_episode:depth_cost_weight + norm_std_early_nodes:depth_cost_weight + 1\"\n",
    "res = smf.ols(formula=formula, data=grouped_data).fit(\n",
    "                    missing=\"drop\"\n",
    "                )\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
