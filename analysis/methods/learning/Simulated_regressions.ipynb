{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping experiment setting to variance and std on early node\n",
    "mapping = {\n",
    "            'cogsci_learning': [-8, -4, 4, 8],\n",
    "            'mini_variance'  : [-2, -1, 1, 2],\n",
    "            'zero_variance'  : [1, 1, 1, 1],\n",
    "            'large_variance' : [-48, -24, 24, 48],\n",
    "            'high_increasing': [-4, -2, 2, 4]\n",
    "                          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "considered_experiment_settings = [\"high_increasing\", \"large_variance\", \"cogsci_learning\", \"mini_variance\", \"zero_variance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.DataFrame()\n",
    "for experiment_setting in considered_experiment_settings:\n",
    "    data_in = pd.read_csv(f\"data/processed/simulated/{experiment_setting}/MCL/linear_depth/search_space/1729_depth_only_baseline_null.csv\")\n",
    "    data_in['experiment_setting']= experiment_setting\n",
    "    data = pd.concat([data, data_in])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column with variance and std of the experiment settings\n",
    "data[\"std_early_nodes\"] = data[\"experiment_setting\"].apply(lambda experiment_setting: np.std(mapping[experiment_setting]))\n",
    "data[\"variance_early_nodes\"] = data[\"experiment_setting\"].apply(lambda experiment_setting: np.var(mapping[experiment_setting]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## normalization\n",
    "# variance\n",
    "data[\"norm_variance_early_nodes\"] = (\n",
    "                                    (data[\"variance_early_nodes\"]-data[\"variance_early_nodes\"].min())/\n",
    "                                    (data[\"variance_early_nodes\"].max()-data[\"variance_early_nodes\"].min()))\n",
    "# std\n",
    "data[\"norm_std_early_nodes\"]      = (\n",
    "                                    (data[\"std_early_nodes\"]-data[\"std_early_nodes\"].min())/\n",
    "                                    (data[\"std_early_nodes\"].max()-data[\"std_early_nodes\"].min()))\n",
    "# data[\"norm_std_early_nodes\"] = preprocessing.Normalizer(data[\"std_early_nodes\"])\n",
    "# data[\"norm_variance_early_nodes\"] = preprocessing.Normalizer(data[\"variance_early_nodes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>w</th>\n",
       "      <th>taken_paths</th>\n",
       "      <th>costs</th>\n",
       "      <th>loss</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>trial_id</th>\n",
       "      <th>i_episode</th>\n",
       "      <th>actions</th>\n",
       "      <th>...</th>\n",
       "      <th>num_late</th>\n",
       "      <th>num_clicks</th>\n",
       "      <th>unbounded_present_bias</th>\n",
       "      <th>unbounded_loss</th>\n",
       "      <th>state</th>\n",
       "      <th>experiment_setting</th>\n",
       "      <th>std_early_nodes</th>\n",
       "      <th>variance_early_nodes</th>\n",
       "      <th>norm_variance_early_nodes</th>\n",
       "      <th>norm_std_early_nodes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[54.0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.0, -2.0, 8.0, 48.0, -24.0, 2.0, -4.0, -48.0...</td>\n",
       "      <td>3827219843471436276</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0, Cat, Cat, Cat, Cat, Cat, Cat, Cat, Cat, Ca...</td>\n",
       "      <td>high_increasing</td>\n",
       "      <td>3.162278</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 15.5454392236338, 48.857094702...</td>\n",
       "      <td>[5, 6, 8]</td>\n",
       "      <td>[-1.0, -1.0, -1.0, 20.0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.0, -2.0, -4.0, -24.0, -48.0, 4.0, -8.0, 24....</td>\n",
       "      <td>-4289689371375290671</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>(0, Cat, Cat, Cat, Cat, Cat, Cat, Cat, Cat, Ca...</td>\n",
       "      <td>high_increasing</td>\n",
       "      <td>3.162278</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 15.5454392236338, 48.857094702...</td>\n",
       "      <td>[5, 6, 8]</td>\n",
       "      <td>[-1.0, -1.0, -1.0, 20.0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.0, -2.0, -4.0, -24.0, -48.0, 4.0, -8.0, 24....</td>\n",
       "      <td>-4289689371375290671</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>(0, Cat, Cat, Cat, Cat, Cat, Cat, Cat, Cat, -4...</td>\n",
       "      <td>high_increasing</td>\n",
       "      <td>3.162278</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 15.5454392236338, 48.857094702...</td>\n",
       "      <td>[5, 6, 8]</td>\n",
       "      <td>[-1.0, -1.0, -1.0, 20.0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.0, -2.0, -4.0, -24.0, -48.0, 4.0, -8.0, 24....</td>\n",
       "      <td>-4289689371375290671</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>(0, -2.0, Cat, Cat, Cat, Cat, Cat, Cat, Cat, -...</td>\n",
       "      <td>high_increasing</td>\n",
       "      <td>3.162278</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 15.5454392236338, 48.857094702...</td>\n",
       "      <td>[5, 6, 8]</td>\n",
       "      <td>[-1.0, -1.0, -1.0, 20.0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.0, -2.0, -4.0, -24.0, -48.0, 4.0, -8.0, 24....</td>\n",
       "      <td>-4289689371375290671</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>(0, -2.0, Cat, Cat, Cat, 4.0, Cat, Cat, Cat, -...</td>\n",
       "      <td>high_increasing</td>\n",
       "      <td>3.162278</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  \\\n",
       "0           0             0   \n",
       "1           1             1   \n",
       "2           2             1   \n",
       "3           3             1   \n",
       "4           4             1   \n",
       "\n",
       "                                                   w taken_paths  \\\n",
       "0                                    [0, 0, 0, 0, 0]   [1, 2, 3]   \n",
       "1  [0.0, 0.0, 0.0, 15.5454392236338, 48.857094702...   [5, 6, 8]   \n",
       "2  [0.0, 0.0, 0.0, 15.5454392236338, 48.857094702...   [5, 6, 8]   \n",
       "3  [0.0, 0.0, 0.0, 15.5454392236338, 48.857094702...   [5, 6, 8]   \n",
       "4  [0.0, 0.0, 0.0, 15.5454392236338, 48.857094702...   [5, 6, 8]   \n",
       "\n",
       "                      costs  loss  \\\n",
       "0                    [54.0]   NaN   \n",
       "1  [-1.0, -1.0, -1.0, 20.0]   NaN   \n",
       "2  [-1.0, -1.0, -1.0, 20.0]   NaN   \n",
       "3  [-1.0, -1.0, -1.0, 20.0]   NaN   \n",
       "4  [-1.0, -1.0, -1.0, 20.0]   NaN   \n",
       "\n",
       "                                        ground_truth             trial_id  \\\n",
       "0  [0.0, -2.0, 8.0, 48.0, -24.0, 2.0, -4.0, -48.0...  3827219843471436276   \n",
       "1  [0.0, -2.0, -4.0, -24.0, -48.0, 4.0, -8.0, 24.... -4289689371375290671   \n",
       "2  [0.0, -2.0, -4.0, -24.0, -48.0, 4.0, -8.0, 24.... -4289689371375290671   \n",
       "3  [0.0, -2.0, -4.0, -24.0, -48.0, 4.0, -8.0, 24.... -4289689371375290671   \n",
       "4  [0.0, -2.0, -4.0, -24.0, -48.0, 4.0, -8.0, 24.... -4289689371375290671   \n",
       "\n",
       "   i_episode  actions  ...  num_late num_clicks unbounded_present_bias  \\\n",
       "0          0        0  ...     False      False                    0.0   \n",
       "1          1        9  ...     False       True                    8.0   \n",
       "2          1        1  ...     False       True                    8.0   \n",
       "3          1        5  ...     False       True                    8.0   \n",
       "4          1        0  ...     False      False                    8.0   \n",
       "\n",
       "   unbounded_loss                                              state  \\\n",
       "0             0.0  (0, Cat, Cat, Cat, Cat, Cat, Cat, Cat, Cat, Ca...   \n",
       "1           -28.0  (0, Cat, Cat, Cat, Cat, Cat, Cat, Cat, Cat, Ca...   \n",
       "2           -28.0  (0, Cat, Cat, Cat, Cat, Cat, Cat, Cat, Cat, -4...   \n",
       "3           -28.0  (0, -2.0, Cat, Cat, Cat, Cat, Cat, Cat, Cat, -...   \n",
       "4           -28.0  (0, -2.0, Cat, Cat, Cat, 4.0, Cat, Cat, Cat, -...   \n",
       "\n",
       "  experiment_setting std_early_nodes variance_early_nodes  \\\n",
       "0    high_increasing        3.162278                 10.0   \n",
       "1    high_increasing        3.162278                 10.0   \n",
       "2    high_increasing        3.162278                 10.0   \n",
       "3    high_increasing        3.162278                 10.0   \n",
       "4    high_increasing        3.162278                 10.0   \n",
       "\n",
       "  norm_variance_early_nodes  norm_std_early_nodes  \n",
       "0                  0.006944              0.083333  \n",
       "1                  0.006944              0.083333  \n",
       "2                  0.006944              0.083333  \n",
       "3                  0.006944              0.083333  \n",
       "4                  0.006944              0.083333  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 0.1', 'w', 'taken_paths', 'costs', 'loss',\n",
       "       'ground_truth', 'trial_id', 'i_episode', 'actions', 'return',\n",
       "       'full_actions', 'sim_experiment_setting', 'sim_model_yaml',\n",
       "       'sim_feature_yaml', 'sim_prior_json', 'sim_constant_yaml',\n",
       "       'sim_cost_function', 'sim_cost_parameter_values', 'sim_num_simulated',\n",
       "       'sim_num_trials', 'static_cost_weight', 'depth_cost_weight', 'pid',\n",
       "       'num_early', 'num_middle', 'num_late', 'num_clicks',\n",
       "       'unbounded_present_bias', 'unbounded_loss', 'state',\n",
       "       'experiment_setting', 'std_early_nodes', 'variance_early_nodes',\n",
       "       'norm_variance_early_nodes', 'norm_std_early_nodes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group data by factors\n",
    "grouped_data = data.groupby([\"pid\", \"i_episode\", \"sim_cost_parameter_values\", \"sim_experiment_setting\"], as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>i_episode</th>\n",
       "      <th>sim_cost_parameter_values</th>\n",
       "      <th>sim_experiment_setting</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>loss</th>\n",
       "      <th>trial_id</th>\n",
       "      <th>actions</th>\n",
       "      <th>return</th>\n",
       "      <th>...</th>\n",
       "      <th>num_early</th>\n",
       "      <th>num_middle</th>\n",
       "      <th>num_late</th>\n",
       "      <th>num_clicks</th>\n",
       "      <th>unbounded_present_bias</th>\n",
       "      <th>unbounded_loss</th>\n",
       "      <th>std_early_nodes</th>\n",
       "      <th>variance_early_nodes</th>\n",
       "      <th>norm_variance_early_nodes</th>\n",
       "      <th>norm_std_early_nodes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0,2.5</td>\n",
       "      <td>cogsci_learning</td>\n",
       "      <td>5699016.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.439592e+19</td>\n",
       "      <td>8.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.973666</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0,2.5</td>\n",
       "      <td>high_increasing</td>\n",
       "      <td>3495651.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.702437e+19</td>\n",
       "      <td>11.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>6.324555</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0,2.5</td>\n",
       "      <td>large_variance</td>\n",
       "      <td>4156537.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.118975e+19</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-77.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>75.894664</td>\n",
       "      <td>2880.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0,2.5</td>\n",
       "      <td>mini_variance</td>\n",
       "      <td>5119206.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.149878e+19</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-189.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-210.0</td>\n",
       "      <td>4.743416</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0,2.5</td>\n",
       "      <td>zero_variance</td>\n",
       "      <td>3645513.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.813679e+19</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-144.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pid  i_episode sim_cost_parameter_values sim_experiment_setting  \\\n",
       "0    0          0                  -1.0,2.5        cogsci_learning   \n",
       "1    0          0                  -1.0,2.5        high_increasing   \n",
       "2    0          0                  -1.0,2.5         large_variance   \n",
       "3    0          0                  -1.0,2.5          mini_variance   \n",
       "4    0          0                  -1.0,2.5          zero_variance   \n",
       "\n",
       "   Unnamed: 0  Unnamed: 0.1  loss      trial_id  actions  return  ...  \\\n",
       "0   5699016.0           0.0   0.0  2.439592e+19      8.0   120.0  ...   \n",
       "1   3495651.0           0.0   0.0 -1.702437e+19     11.0    31.0  ...   \n",
       "2   4156537.0           0.0   0.0 -1.118975e+19      7.0   -77.0  ...   \n",
       "3   5119206.0           0.0   0.0 -1.149878e+19      8.0  -189.0  ...   \n",
       "4   3645513.0           0.0   0.0  1.813679e+19      2.0   -46.0  ...   \n",
       "\n",
       "   num_early  num_middle  num_late  num_clicks  unbounded_present_bias  \\\n",
       "0        1.0         0.0       1.0         2.0                     0.0   \n",
       "1        0.0         0.0       1.0         1.0                     0.0   \n",
       "2        0.0         0.0       1.0         1.0                     0.0   \n",
       "3        1.0         0.0       1.0         2.0                     6.0   \n",
       "4        0.0         1.0       0.0         1.0                     0.0   \n",
       "\n",
       "   unbounded_loss  std_early_nodes  variance_early_nodes  \\\n",
       "0             0.0        18.973666                 120.0   \n",
       "1           -16.0         6.324555                  20.0   \n",
       "2          -224.0        75.894664                2880.0   \n",
       "3          -210.0         4.743416                   7.5   \n",
       "4          -144.0         0.000000                   0.0   \n",
       "\n",
       "   norm_variance_early_nodes  norm_std_early_nodes  \n",
       "0                   0.083333              0.500000  \n",
       "1                   0.013889              0.166667  \n",
       "2                   2.000000              2.000000  \n",
       "3                   0.005208              0.125000  \n",
       "4                   0.000000              0.000000  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. early_node ~ depth_cost_weight and i_episode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>num_early</td>    <th>  R-squared:         </th>  <td>   0.005</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.005</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   5183.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 06 Jan 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:20:17</td>     <th>  Log-Likelihood:    </th> <td>-5.2421e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>3400000</td>     <th>  AIC:               </th>  <td>1.048e+07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>3399996</td>     <th>  BIC:               </th>  <td>1.048e+07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                  <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                   <td>    0.7834</td> <td>    0.001</td> <td>  643.347</td> <td> 0.000</td> <td>    0.781</td> <td>    0.786</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>i_episode</th>                   <td>   -0.0015</td> <td> 2.13e-05</td> <td>  -68.849</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>i_episode:depth_cost_weight</th> <td>-2.859e-05</td> <td> 1.85e-06</td> <td>  -15.440</td> <td> 0.000</td> <td>-3.22e-05</td> <td> -2.5e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>depth_cost_weight</th>           <td>   -0.0043</td> <td>    0.000</td> <td>  -40.353</td> <td> 0.000</td> <td>   -0.004</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>559576.601</td> <th>  Durbin-Watson:     </th>  <td>   1.946</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>895813.867</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td> 1.257</td>   <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>        <td> 2.939</td>   <th>  Cond. No.          </th>  <td>1.29e+03</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.29e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              num_early   R-squared:                       0.005\n",
       "Model:                            OLS   Adj. R-squared:                  0.005\n",
       "Method:                 Least Squares   F-statistic:                     5183.\n",
       "Date:                Fri, 06 Jan 2023   Prob (F-statistic):               0.00\n",
       "Time:                        21:20:17   Log-Likelihood:            -5.2421e+06\n",
       "No. Observations:             3400000   AIC:                         1.048e+07\n",
       "Df Residuals:                 3399996   BIC:                         1.048e+07\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================================\n",
       "                                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------\n",
       "Intercept                       0.7834      0.001    643.347      0.000       0.781       0.786\n",
       "i_episode                      -0.0015   2.13e-05    -68.849      0.000      -0.002      -0.001\n",
       "i_episode:depth_cost_weight -2.859e-05   1.85e-06    -15.440      0.000   -3.22e-05    -2.5e-05\n",
       "depth_cost_weight              -0.0043      0.000    -40.353      0.000      -0.004      -0.004\n",
       "==============================================================================\n",
       "Omnibus:                   559576.601   Durbin-Watson:                   1.946\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           895813.867\n",
       "Skew:                           1.257   Prob(JB):                         0.00\n",
       "Kurtosis:                       2.939   Cond. No.                     1.29e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.29e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula = \"num_early ~ i_episode + i_episode:depth_cost_weight + depth_cost_weight + 1\"\n",
    "res = smf.ols(formula=formula, data=grouped_data).fit(\n",
    "                    missing=\"drop\"\n",
    "                )\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>num_early</td>    <th>  R-squared:         </th>  <td>   0.016</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.016</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   3639.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 06 Jan 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:20:25</td>     <th>  Log-Likelihood:    </th> <td>-1.0455e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>680000</td>      <th>  AIC:               </th>  <td>2.091e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>679996</td>      <th>  BIC:               </th>  <td>2.091e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                  <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                   <td>    0.7766</td> <td>    0.003</td> <td>  285.595</td> <td> 0.000</td> <td>    0.771</td> <td>    0.782</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>i_episode</th>                   <td>   -0.0024</td> <td> 4.75e-05</td> <td>  -50.243</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>i_episode:depth_cost_weight</th> <td>  3.22e-06</td> <td> 3.82e-06</td> <td>    0.844</td> <td> 0.399</td> <td>-4.26e-06</td> <td> 1.07e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>depth_cost_weight</th>           <td>   -0.0103</td> <td>    0.000</td> <td>  -47.457</td> <td> 0.000</td> <td>   -0.011</td> <td>   -0.010</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>123625.866</td> <th>  Durbin-Watson:     </th>  <td>   1.986</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>206557.958</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td> 1.347</td>   <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>        <td> 3.183</td>   <th>  Cond. No.          </th>  <td>1.42e+03</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.42e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              num_early   R-squared:                       0.016\n",
       "Model:                            OLS   Adj. R-squared:                  0.016\n",
       "Method:                 Least Squares   F-statistic:                     3639.\n",
       "Date:                Fri, 06 Jan 2023   Prob (F-statistic):               0.00\n",
       "Time:                        21:20:25   Log-Likelihood:            -1.0455e+06\n",
       "No. Observations:              680000   AIC:                         2.091e+06\n",
       "Df Residuals:                  679996   BIC:                         2.091e+06\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================================\n",
       "                                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------\n",
       "Intercept                       0.7766      0.003    285.595      0.000       0.771       0.782\n",
       "i_episode                      -0.0024   4.75e-05    -50.243      0.000      -0.002      -0.002\n",
       "i_episode:depth_cost_weight   3.22e-06   3.82e-06      0.844      0.399   -4.26e-06    1.07e-05\n",
       "depth_cost_weight              -0.0103      0.000    -47.457      0.000      -0.011      -0.010\n",
       "==============================================================================\n",
       "Omnibus:                   123625.866   Durbin-Watson:                   1.986\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           206557.958\n",
       "Skew:                           1.347   Prob(JB):                         0.00\n",
       "Kurtosis:                       3.183   Cond. No.                     1.42e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.42e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. cogsci_learning\n",
    "cogsci_learning_grouped_data = grouped_data.loc[grouped_data['sim_experiment_setting'] == 'cogsci_learning']\n",
    "res = smf.ols(formula=formula, data=cogsci_learning_grouped_data).fit(\n",
    "                    missing=\"drop\"\n",
    "                )\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>num_early</td>    <th>  R-squared:         </th>  <td>   0.016</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.016</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   3626.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 06 Jan 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:20:31</td>     <th>  Log-Likelihood:    </th> <td>-1.0080e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>680000</td>      <th>  AIC:               </th>  <td>2.016e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>679996</td>      <th>  BIC:               </th>  <td>2.016e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                  <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                   <td>    0.7231</td> <td>    0.003</td> <td>  281.930</td> <td> 0.000</td> <td>    0.718</td> <td>    0.728</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>i_episode</th>                   <td>   -0.0029</td> <td> 4.48e-05</td> <td>  -65.052</td> <td> 0.000</td> <td>   -0.003</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>i_episode:depth_cost_weight</th> <td>   -0.0001</td> <td> 4.41e-06</td> <td>  -26.155</td> <td> 0.000</td> <td>   -0.000</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>depth_cost_weight</th>           <td>   -0.0046</td> <td>    0.000</td> <td>  -18.436</td> <td> 0.000</td> <td>   -0.005</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>160977.288</td> <th>  Durbin-Watson:     </th>  <td>   1.932</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>301599.642</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td> 1.570</td>   <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>        <td> 3.883</td>   <th>  Cond. No.          </th>  <td>1.13e+03</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.13e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              num_early   R-squared:                       0.016\n",
       "Model:                            OLS   Adj. R-squared:                  0.016\n",
       "Method:                 Least Squares   F-statistic:                     3626.\n",
       "Date:                Fri, 06 Jan 2023   Prob (F-statistic):               0.00\n",
       "Time:                        21:20:31   Log-Likelihood:            -1.0080e+06\n",
       "No. Observations:              680000   AIC:                         2.016e+06\n",
       "Df Residuals:                  679996   BIC:                         2.016e+06\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================================\n",
       "                                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------\n",
       "Intercept                       0.7231      0.003    281.930      0.000       0.718       0.728\n",
       "i_episode                      -0.0029   4.48e-05    -65.052      0.000      -0.003      -0.003\n",
       "i_episode:depth_cost_weight    -0.0001   4.41e-06    -26.155      0.000      -0.000      -0.000\n",
       "depth_cost_weight              -0.0046      0.000    -18.436      0.000      -0.005      -0.004\n",
       "==============================================================================\n",
       "Omnibus:                   160977.288   Durbin-Watson:                   1.932\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           301599.642\n",
       "Skew:                           1.570   Prob(JB):                         0.00\n",
       "Kurtosis:                       3.883   Cond. No.                     1.13e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.13e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_increasing_grouped_data = grouped_data.loc[grouped_data['sim_experiment_setting'] == 'high_increasing']\n",
    "res = smf.ols(formula=formula, data=high_increasing_grouped_data).fit(\n",
    "                    missing=\"drop\"\n",
    "                )\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>num_early</td>    <th>  R-squared:         </th>  <td>   0.005</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.005</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   1160.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 06 Jan 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:20:35</td>     <th>  Log-Likelihood:    </th> <td>-1.0986e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>680000</td>      <th>  AIC:               </th>  <td>2.197e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>679996</td>      <th>  BIC:               </th>  <td>2.197e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                  <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                   <td>    1.0617</td> <td>    0.003</td> <td>  361.682</td> <td> 0.000</td> <td>    1.056</td> <td>    1.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>i_episode</th>                   <td>    0.0026</td> <td> 5.13e-05</td> <td>   51.596</td> <td> 0.000</td> <td>    0.003</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>i_episode:depth_cost_weight</th> <td> 7.885e-05</td> <td>  3.7e-06</td> <td>   21.306</td> <td> 0.000</td> <td> 7.16e-05</td> <td> 8.61e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>depth_cost_weight</th>           <td>   -0.0062</td> <td>    0.000</td> <td>  -29.171</td> <td> 0.000</td> <td>   -0.007</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>7290789.236</td> <th>  Durbin-Watson:     </th> <td>   1.995</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>    <th>  Jarque-Bera (JB):  </th> <td>76724.692</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td> 0.446</td>    <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>        <td> 1.617</td>    <th>  Cond. No.          </th> <td>1.58e+03</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.58e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              num_early   R-squared:                       0.005\n",
       "Model:                            OLS   Adj. R-squared:                  0.005\n",
       "Method:                 Least Squares   F-statistic:                     1160.\n",
       "Date:                Fri, 06 Jan 2023   Prob (F-statistic):               0.00\n",
       "Time:                        21:20:35   Log-Likelihood:            -1.0986e+06\n",
       "No. Observations:              680000   AIC:                         2.197e+06\n",
       "Df Residuals:                  679996   BIC:                         2.197e+06\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================================\n",
       "                                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------\n",
       "Intercept                       1.0617      0.003    361.682      0.000       1.056       1.067\n",
       "i_episode                       0.0026   5.13e-05     51.596      0.000       0.003       0.003\n",
       "i_episode:depth_cost_weight  7.885e-05    3.7e-06     21.306      0.000    7.16e-05    8.61e-05\n",
       "depth_cost_weight              -0.0062      0.000    -29.171      0.000      -0.007      -0.006\n",
       "==============================================================================\n",
       "Omnibus:                  7290789.236   Durbin-Watson:                   1.995\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            76724.692\n",
       "Skew:                           0.446   Prob(JB):                         0.00\n",
       "Kurtosis:                       1.617   Cond. No.                     1.58e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.58e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. large_variance\n",
    "large_variance_grouped_data = grouped_data.loc[grouped_data['sim_experiment_setting'] == 'large_variance']\n",
    "res = smf.ols(formula=formula, data=large_variance_grouped_data).fit(\n",
    "                    missing=\"drop\"\n",
    "                )\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>num_early</td>    <th>  R-squared:         </th>  <td>   0.009</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.009</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   2068.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 06 Jan 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:20:39</td>     <th>  Log-Likelihood:    </th> <td>-1.0008e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>680000</td>      <th>  AIC:               </th>  <td>2.002e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>679996</td>      <th>  BIC:               </th>  <td>2.002e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                  <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                   <td>    0.6920</td> <td>    0.003</td> <td>  272.639</td> <td> 0.000</td> <td>    0.687</td> <td>    0.697</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>i_episode</th>                   <td>   -0.0024</td> <td> 4.43e-05</td> <td>  -53.733</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>i_episode:depth_cost_weight</th> <td>-9.712e-05</td> <td> 4.18e-06</td> <td>  -23.212</td> <td> 0.000</td> <td>   -0.000</td> <td>-8.89e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>depth_cost_weight</th>           <td>   -0.0021</td> <td>    0.000</td> <td>   -8.812</td> <td> 0.000</td> <td>   -0.003</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>164057.367</td> <th>  Durbin-Watson:     </th>  <td>   1.876</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>310655.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td> 1.588</td>   <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>        <td> 3.939</td>   <th>  Cond. No.          </th>  <td>1.17e+03</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.17e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              num_early   R-squared:                       0.009\n",
       "Model:                            OLS   Adj. R-squared:                  0.009\n",
       "Method:                 Least Squares   F-statistic:                     2068.\n",
       "Date:                Fri, 06 Jan 2023   Prob (F-statistic):               0.00\n",
       "Time:                        21:20:39   Log-Likelihood:            -1.0008e+06\n",
       "No. Observations:              680000   AIC:                         2.002e+06\n",
       "Df Residuals:                  679996   BIC:                         2.002e+06\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================================\n",
       "                                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------\n",
       "Intercept                       0.6920      0.003    272.639      0.000       0.687       0.697\n",
       "i_episode                      -0.0024   4.43e-05    -53.733      0.000      -0.002      -0.002\n",
       "i_episode:depth_cost_weight -9.712e-05   4.18e-06    -23.212      0.000      -0.000   -8.89e-05\n",
       "depth_cost_weight              -0.0021      0.000     -8.812      0.000      -0.003      -0.002\n",
       "==============================================================================\n",
       "Omnibus:                   164057.367   Durbin-Watson:                   1.876\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           310655.061\n",
       "Skew:                           1.588   Prob(JB):                         0.00\n",
       "Kurtosis:                       3.939   Cond. No.                     1.17e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.17e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. mini_variance\n",
    "mini_variance_grouped_data = grouped_data.loc[grouped_data['sim_experiment_setting'] == 'mini_variance']\n",
    "res = smf.ols(formula=formula, data=mini_variance_grouped_data).fit(\n",
    "                    missing=\"drop\"\n",
    "                )\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>num_early</td>    <th>  R-squared:         </th>  <td>   0.007</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.007</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   1623.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 06 Jan 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:20:42</td>     <th>  Log-Likelihood:    </th> <td>-9.8647e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>680000</td>      <th>  AIC:               </th>  <td>1.973e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>679996</td>      <th>  BIC:               </th>  <td>1.973e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                  <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                   <td>    0.6474</td> <td>    0.002</td> <td>  260.199</td> <td> 0.000</td> <td>    0.643</td> <td>    0.652</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>i_episode</th>                   <td>   -0.0021</td> <td> 4.34e-05</td> <td>  -47.357</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>i_episode:depth_cost_weight</th> <td>   -0.0001</td> <td> 4.41e-06</td> <td>  -23.092</td> <td> 0.000</td> <td>   -0.000</td> <td>-9.31e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>depth_cost_weight</th>           <td>    0.0107</td> <td>    0.000</td> <td>   42.088</td> <td> 0.000</td> <td>    0.010</td> <td>    0.011</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>187883.566</td> <th>  Durbin-Watson:     </th>  <td>   1.940</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>388989.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td> 1.719</td>   <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>        <td> 4.383</td>   <th>  Cond. No.          </th>  <td>1.10e+03</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.1e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              num_early   R-squared:                       0.007\n",
       "Model:                            OLS   Adj. R-squared:                  0.007\n",
       "Method:                 Least Squares   F-statistic:                     1623.\n",
       "Date:                Fri, 06 Jan 2023   Prob (F-statistic):               0.00\n",
       "Time:                        21:20:42   Log-Likelihood:            -9.8647e+05\n",
       "No. Observations:              680000   AIC:                         1.973e+06\n",
       "Df Residuals:                  679996   BIC:                         1.973e+06\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================================\n",
       "                                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------\n",
       "Intercept                       0.6474      0.002    260.199      0.000       0.643       0.652\n",
       "i_episode                      -0.0021   4.34e-05    -47.357      0.000      -0.002      -0.002\n",
       "i_episode:depth_cost_weight    -0.0001   4.41e-06    -23.092      0.000      -0.000   -9.31e-05\n",
       "depth_cost_weight               0.0107      0.000     42.088      0.000       0.010       0.011\n",
       "==============================================================================\n",
       "Omnibus:                   187883.566   Durbin-Watson:                   1.940\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           388989.177\n",
       "Skew:                           1.719   Prob(JB):                         0.00\n",
       "Kurtosis:                       4.383   Cond. No.                     1.10e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.1e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. zero_variance\n",
    "zero_variance_grouped_data = grouped_data.loc[grouped_data['sim_experiment_setting'] == 'zero_variance']\n",
    "res = smf.ols(formula=formula, data=zero_variance_grouped_data).fit(\n",
    "                    missing=\"drop\"\n",
    "                )\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(cogsci_learning_grouped_data[\"sim_experiment_setting\"].unique())\n",
    "#print(high_increasing_grouped_data[\"sim_experiment_setting\"].unique())\n",
    "#print(large_variance_grouped_data[\"sim_experiment_setting\"].unique())\n",
    "#print(mini_variance_grouped_data[\"sim_experiment_setting\"].unique())\n",
    "#print(zero_variance_grouped_data[\"sim_experiment_setting\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. early_node ~ experiment_setting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>num_early</td>    <th>  R-squared:         </th>  <td>   0.056</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.056</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>1.063e+04</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 06 Jan 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:42:04</td>     <th>  Log-Likelihood:    </th> <td>-5.1518e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>3400000</td>     <th>  AIC:               </th>  <td>1.030e+07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>3399980</td>     <th>  BIC:               </th>  <td>1.030e+07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    19</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                                    <td></td>                                       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                                             <td>    0.7766</td> <td>    0.003</td> <td>  292.018</td> <td> 0.000</td> <td>    0.771</td> <td>    0.782</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sim_experiment_setting[T.high_increasing]</th>                             <td>   -0.0534</td> <td>    0.004</td> <td>  -14.228</td> <td> 0.000</td> <td>   -0.061</td> <td>   -0.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sim_experiment_setting[T.large_variance]</th>                              <td>    0.2851</td> <td>    0.004</td> <td>   75.876</td> <td> 0.000</td> <td>    0.278</td> <td>    0.292</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sim_experiment_setting[T.mini_variance]</th>                               <td>   -0.0845</td> <td>    0.004</td> <td>  -22.515</td> <td> 0.000</td> <td>   -0.092</td> <td>   -0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sim_experiment_setting[T.zero_variance]</th>                               <td>   -0.1292</td> <td>    0.004</td> <td>  -34.385</td> <td> 0.000</td> <td>   -0.137</td> <td>   -0.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>i_episode</th>                                                             <td>   -0.0024</td> <td> 4.65e-05</td> <td>  -51.373</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sim_experiment_setting[T.high_increasing]:i_episode</th>                   <td>   -0.0005</td> <td> 6.56e-05</td> <td>   -8.025</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sim_experiment_setting[T.large_variance]:i_episode</th>                    <td>    0.0050</td> <td> 6.57e-05</td> <td>   76.660</td> <td> 0.000</td> <td>    0.005</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sim_experiment_setting[T.mini_variance]:i_episode</th>                     <td> 4.513e-06</td> <td> 6.56e-05</td> <td>    0.069</td> <td> 0.945</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sim_experiment_setting[T.zero_variance]:i_episode</th>                     <td>    0.0003</td> <td> 6.56e-05</td> <td>    5.051</td> <td> 0.000</td> <td>    0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>i_episode:depth_cost_weight</th>                                           <td>  3.22e-06</td> <td> 3.73e-06</td> <td>    0.863</td> <td> 0.388</td> <td>-4.09e-06</td> <td> 1.05e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sim_experiment_setting[T.high_increasing]:i_episode:depth_cost_weight</th> <td>   -0.0001</td> <td> 5.89e-06</td> <td>  -20.132</td> <td> 0.000</td> <td>   -0.000</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sim_experiment_setting[T.large_variance]:i_episode:depth_cost_weight</th>  <td> 7.563e-05</td> <td> 5.01e-06</td> <td>   15.086</td> <td> 0.000</td> <td> 6.58e-05</td> <td> 8.55e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sim_experiment_setting[T.mini_variance]:i_episode:depth_cost_weight</th>   <td>   -0.0001</td> <td> 5.75e-06</td> <td>  -17.462</td> <td> 0.000</td> <td>   -0.000</td> <td>-8.91e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sim_experiment_setting[T.zero_variance]:i_episode:depth_cost_weight</th>   <td>   -0.0001</td> <td>    6e-06</td> <td>  -17.490</td> <td> 0.000</td> <td>   -0.000</td> <td>-9.32e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>depth_cost_weight</th>                                                     <td>   -0.0103</td> <td>    0.000</td> <td>  -48.524</td> <td> 0.000</td> <td>   -0.011</td> <td>   -0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sim_experiment_setting[T.high_increasing]:depth_cost_weight</th>           <td>    0.0057</td> <td>    0.000</td> <td>   17.118</td> <td> 0.000</td> <td>    0.005</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sim_experiment_setting[T.large_variance]:depth_cost_weight</th>            <td>    0.0041</td> <td>    0.000</td> <td>   14.335</td> <td> 0.000</td> <td>    0.004</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sim_experiment_setting[T.mini_variance]:depth_cost_weight</th>             <td>    0.0082</td> <td>    0.000</td> <td>   25.281</td> <td> 0.000</td> <td>    0.008</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sim_experiment_setting[T.zero_variance]:depth_cost_weight</th>             <td>    0.0210</td> <td>    0.000</td> <td>   60.992</td> <td> 0.000</td> <td>    0.020</td> <td>    0.022</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>562601.603</td> <th>  Durbin-Watson:     </th>  <td>   1.916</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>898401.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td> 1.255</td>   <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>        <td> 3.199</td>   <th>  Cond. No.          </th>  <td>7.58e+03</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 7.58e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              num_early   R-squared:                       0.056\n",
       "Model:                            OLS   Adj. R-squared:                  0.056\n",
       "Method:                 Least Squares   F-statistic:                 1.063e+04\n",
       "Date:                Fri, 06 Jan 2023   Prob (F-statistic):               0.00\n",
       "Time:                        20:42:04   Log-Likelihood:            -5.1518e+06\n",
       "No. Observations:             3400000   AIC:                         1.030e+07\n",
       "Df Residuals:                 3399980   BIC:                         1.030e+07\n",
       "Df Model:                          19                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=========================================================================================================================================\n",
       "                                                                            coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                                                 0.7766      0.003    292.018      0.000       0.771       0.782\n",
       "sim_experiment_setting[T.high_increasing]                                -0.0534      0.004    -14.228      0.000      -0.061      -0.046\n",
       "sim_experiment_setting[T.large_variance]                                  0.2851      0.004     75.876      0.000       0.278       0.292\n",
       "sim_experiment_setting[T.mini_variance]                                  -0.0845      0.004    -22.515      0.000      -0.092      -0.077\n",
       "sim_experiment_setting[T.zero_variance]                                  -0.1292      0.004    -34.385      0.000      -0.137      -0.122\n",
       "i_episode                                                                -0.0024   4.65e-05    -51.373      0.000      -0.002      -0.002\n",
       "sim_experiment_setting[T.high_increasing]:i_episode                      -0.0005   6.56e-05     -8.025      0.000      -0.001      -0.000\n",
       "sim_experiment_setting[T.large_variance]:i_episode                        0.0050   6.57e-05     76.660      0.000       0.005       0.005\n",
       "sim_experiment_setting[T.mini_variance]:i_episode                      4.513e-06   6.56e-05      0.069      0.945      -0.000       0.000\n",
       "sim_experiment_setting[T.zero_variance]:i_episode                         0.0003   6.56e-05      5.051      0.000       0.000       0.000\n",
       "i_episode:depth_cost_weight                                             3.22e-06   3.73e-06      0.863      0.388   -4.09e-06    1.05e-05\n",
       "sim_experiment_setting[T.high_increasing]:i_episode:depth_cost_weight    -0.0001   5.89e-06    -20.132      0.000      -0.000      -0.000\n",
       "sim_experiment_setting[T.large_variance]:i_episode:depth_cost_weight   7.563e-05   5.01e-06     15.086      0.000    6.58e-05    8.55e-05\n",
       "sim_experiment_setting[T.mini_variance]:i_episode:depth_cost_weight      -0.0001   5.75e-06    -17.462      0.000      -0.000   -8.91e-05\n",
       "sim_experiment_setting[T.zero_variance]:i_episode:depth_cost_weight      -0.0001      6e-06    -17.490      0.000      -0.000   -9.32e-05\n",
       "depth_cost_weight                                                        -0.0103      0.000    -48.524      0.000      -0.011      -0.010\n",
       "sim_experiment_setting[T.high_increasing]:depth_cost_weight               0.0057      0.000     17.118      0.000       0.005       0.006\n",
       "sim_experiment_setting[T.large_variance]:depth_cost_weight                0.0041      0.000     14.335      0.000       0.004       0.005\n",
       "sim_experiment_setting[T.mini_variance]:depth_cost_weight                 0.0082      0.000     25.281      0.000       0.008       0.009\n",
       "sim_experiment_setting[T.zero_variance]:depth_cost_weight                 0.0210      0.000     60.992      0.000       0.020       0.022\n",
       "==============================================================================\n",
       "Omnibus:                   562601.603   Durbin-Watson:                   1.916\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           898401.102\n",
       "Skew:                           1.255   Prob(JB):                         0.00\n",
       "Kurtosis:                       3.199   Cond. No.                     7.58e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 7.58e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula = \"num_early ~ i_episode + i_episode:depth_cost_weight + depth_cost_weight + sim_experiment_setting + sim_experiment_setting:i_episode + sim_experiment_setting:i_episode:depth_cost_weight + sim_experiment_setting:depth_cost_weight + 1\"\n",
    "res = smf.ols(formula=formula, data=grouped_data).fit(\n",
    "                    missing=\"drop\"\n",
    "                )\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 3. early_node ~ norm_variance_early_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All environment_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>num_early</td>    <th>  R-squared:         </th>  <td>   0.119</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.119</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>6.565e+04</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 06 Jan 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:42:23</td>     <th>  Log-Likelihood:    </th> <td>-5.0344e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>3400000</td>     <th>  AIC:               </th>  <td>1.007e+07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>3399992</td>     <th>  BIC:               </th>  <td>1.007e+07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                            <td></td>                               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                             <td>    0.6485</td> <td>    0.001</td> <td>  525.696</td> <td> 0.000</td> <td>    0.646</td> <td>    0.651</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>i_episode</th>                                             <td>   -0.0019</td> <td> 2.16e-05</td> <td>  -88.906</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>i_episode:depth_cost_weight</th>                           <td>-4.081e-05</td> <td> 2.03e-06</td> <td>  -20.108</td> <td> 0.000</td> <td>-4.48e-05</td> <td>-3.68e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>depth_cost_weight</th>                                     <td>   -0.0015</td> <td>    0.000</td> <td>  -12.816</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>norm_variance_early_nodes</th>                             <td>    0.1581</td> <td>    0.001</td> <td>  294.696</td> <td> 0.000</td> <td>    0.157</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>norm_variance_early_nodes:i_episode</th>                   <td>    0.0004</td> <td> 9.37e-06</td> <td>   40.127</td> <td> 0.000</td> <td>    0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>norm_variance_early_nodes:i_episode:depth_cost_weight</th> <td> 1.916e-05</td> <td>  4.3e-07</td> <td>   44.563</td> <td> 0.000</td> <td> 1.83e-05</td> <td>    2e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>norm_variance_early_nodes:depth_cost_weight</th>           <td>    0.0004</td> <td> 2.35e-05</td> <td>   17.179</td> <td> 0.000</td> <td>    0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>619902.746</td> <th>  Durbin-Watson:     </th>  <td>   1.929</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>1018112.631</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td> 1.308</td>   <th>  Prob(JB):          </th>  <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>        <td> 3.583</td>   <th>  Cond. No.          </th>  <td>6.77e+03</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 6.77e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              num_early   R-squared:                       0.119\n",
       "Model:                            OLS   Adj. R-squared:                  0.119\n",
       "Method:                 Least Squares   F-statistic:                 6.565e+04\n",
       "Date:                Fri, 06 Jan 2023   Prob (F-statistic):               0.00\n",
       "Time:                        20:42:23   Log-Likelihood:            -5.0344e+06\n",
       "No. Observations:             3400000   AIC:                         1.007e+07\n",
       "Df Residuals:                 3399992   BIC:                         1.007e+07\n",
       "Df Model:                           7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=========================================================================================================================\n",
       "                                                            coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                                 0.6485      0.001    525.696      0.000       0.646       0.651\n",
       "i_episode                                                -0.0019   2.16e-05    -88.906      0.000      -0.002      -0.002\n",
       "i_episode:depth_cost_weight                           -4.081e-05   2.03e-06    -20.108      0.000   -4.48e-05   -3.68e-05\n",
       "depth_cost_weight                                        -0.0015      0.000    -12.816      0.000      -0.002      -0.001\n",
       "norm_variance_early_nodes                                 0.1581      0.001    294.696      0.000       0.157       0.159\n",
       "norm_variance_early_nodes:i_episode                       0.0004   9.37e-06     40.127      0.000       0.000       0.000\n",
       "norm_variance_early_nodes:i_episode:depth_cost_weight  1.916e-05    4.3e-07     44.563      0.000    1.83e-05       2e-05\n",
       "norm_variance_early_nodes:depth_cost_weight               0.0004   2.35e-05     17.179      0.000       0.000       0.000\n",
       "==============================================================================\n",
       "Omnibus:                   619902.746   Durbin-Watson:                   1.929\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1018112.631\n",
       "Skew:                           1.308   Prob(JB):                         0.00\n",
       "Kurtosis:                       3.583   Cond. No.                     6.77e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 6.77e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula = \"num_early ~ i_episode + i_episode:depth_cost_weight + depth_cost_weight + norm_variance_early_nodes + norm_variance_early_nodes:i_episode + norm_variance_early_nodes:i_episode:depth_cost_weight + norm_variance_early_nodes:depth_cost_weight + 1\"\n",
    "res = smf.ols(formula=formula, data=grouped_data).fit(\n",
    "                    missing=\"drop\"\n",
    "                )\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. early_node ~ norm_std_early_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All experiment settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>num_early</td>    <th>  R-squared:         </th>  <td>   0.152</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.152</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>8.684e+04</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 06 Jan 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:04:46</td>     <th>  Log-Likelihood:    </th> <td>-4.9703e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>3400000</td>     <th>  AIC:               </th>  <td>9.941e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>3399992</td>     <th>  BIC:               </th>  <td>9.941e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                          <td></td>                            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                        <td>    0.5810</td> <td>    0.001</td> <td>  461.654</td> <td> 0.000</td> <td>    0.579</td> <td>    0.583</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>i_episode</th>                                        <td>   -0.0019</td> <td> 2.21e-05</td> <td>  -87.072</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>i_episode:depth_cost_weight</th>                      <td>-4.242e-05</td> <td> 2.11e-06</td> <td>  -20.117</td> <td> 0.000</td> <td>-4.66e-05</td> <td>-3.83e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>depth_cost_weight</th>                                <td>    0.0004</td> <td>    0.000</td> <td>    3.634</td> <td> 0.000</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>norm_std_early_nodes</th>                             <td>    0.1918</td> <td>    0.001</td> <td>  356.089</td> <td> 0.000</td> <td>    0.191</td> <td>    0.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>norm_std_early_nodes:i_episode</th>                   <td>    0.0003</td> <td> 9.42e-06</td> <td>   28.334</td> <td> 0.000</td> <td>    0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>norm_std_early_nodes:i_episode:depth_cost_weight</th> <td> 1.892e-05</td> <td>  4.4e-07</td> <td>   42.959</td> <td> 0.000</td> <td> 1.81e-05</td> <td> 1.98e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>norm_std_early_nodes:depth_cost_weight</th>           <td>    0.0003</td> <td>  2.4e-05</td> <td>   12.879</td> <td> 0.000</td> <td>    0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>605881.398</td> <th>  Durbin-Watson:     </th>  <td>   1.938</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>983329.869</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td> 1.277</td>   <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>        <td> 3.647</td>   <th>  Cond. No.          </th>  <td>7.17e+03</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 7.17e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              num_early   R-squared:                       0.152\n",
       "Model:                            OLS   Adj. R-squared:                  0.152\n",
       "Method:                 Least Squares   F-statistic:                 8.684e+04\n",
       "Date:                Fri, 06 Jan 2023   Prob (F-statistic):               0.00\n",
       "Time:                        21:04:46   Log-Likelihood:            -4.9703e+06\n",
       "No. Observations:             3400000   AIC:                         9.941e+06\n",
       "Df Residuals:                 3399992   BIC:                         9.941e+06\n",
       "Df Model:                           7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================================================\n",
       "                                                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                            0.5810      0.001    461.654      0.000       0.579       0.583\n",
       "i_episode                                           -0.0019   2.21e-05    -87.072      0.000      -0.002      -0.002\n",
       "i_episode:depth_cost_weight                      -4.242e-05   2.11e-06    -20.117      0.000   -4.66e-05   -3.83e-05\n",
       "depth_cost_weight                                    0.0004      0.000      3.634      0.000       0.000       0.001\n",
       "norm_std_early_nodes                                 0.1918      0.001    356.089      0.000       0.191       0.193\n",
       "norm_std_early_nodes:i_episode                       0.0003   9.42e-06     28.334      0.000       0.000       0.000\n",
       "norm_std_early_nodes:i_episode:depth_cost_weight  1.892e-05    4.4e-07     42.959      0.000    1.81e-05    1.98e-05\n",
       "norm_std_early_nodes:depth_cost_weight               0.0003    2.4e-05     12.879      0.000       0.000       0.000\n",
       "==============================================================================\n",
       "Omnibus:                   605881.398   Durbin-Watson:                   1.938\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           983329.869\n",
       "Skew:                           1.277   Prob(JB):                         0.00\n",
       "Kurtosis:                       3.647   Cond. No.                     7.17e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 7.17e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula = \"num_early ~ i_episode + i_episode:depth_cost_weight + depth_cost_weight + norm_std_early_nodes + norm_std_early_nodes:i_episode + norm_std_early_nodes:i_episode:depth_cost_weight + norm_std_early_nodes:depth_cost_weight + 1\"\n",
    "res = smf.ols(formula=formula, data=grouped_data).fit(\n",
    "                    missing=\"drop\"\n",
    "                )\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Individual experiment setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
