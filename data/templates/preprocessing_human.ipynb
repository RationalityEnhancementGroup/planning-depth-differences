{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from download_tools.plugins.mouselab_mdp import preprocess_mouselab_data, add_click_count_columns\n",
    "from download_tools.plugins.survey_html_form import process_html_demographics\n",
    "from download_tools.plugins.survey_multi_choice import score_mouselab_questionnaires, get_mouselab_quiz_name, get_quiz_passer_ids, score_row\n",
    "from download_tools.plugins.survey_text import preprocess_survey_text, get_old_demographics\n",
    "from download_tools.plugins.utils import get_demo_string\n",
    "\n",
    "from datetime import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# paths to use\n",
    "inputs_path = Path(data_path).joinpath('inputs')\n",
    "raw_data_path = Path(data_path).joinpath('raw')\n",
    "processed_data_path = Path(data_path).joinpath(f'processed/{analysis_run}')\n",
    "processed_data_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(inputs_path.joinpath(f\"exp_inputs/rewards/{ground_truth_file}.json\")) as json_file:\n",
    "    ground_truths = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "full_data = {}\n",
    "\n",
    "# read in sessions\n",
    "for run in sessions:\n",
    "    for file_path in raw_data_path.glob(f\"{run}/*.csv\"):\n",
    "        # don't want to save identifiable bonuses\n",
    "        # file, information is already in data\n",
    "        if \"bonuses\" not in str(file_path):\n",
    "            file_name = file_path.stem\n",
    "            curr_data_frame = pd.read_csv(file_path)\n",
    "            curr_data_frame[\"run\"] = run\n",
    "            if file_name not in full_data:\n",
    "                full_data[file_name] = [curr_data_frame]\n",
    "            else:\n",
    "                full_data[file_name].append(curr_data_frame)\n",
    "\n",
    "full_data = {k: pd.concat(v) for k,v in full_data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "individual_variables = full_data[\"general_info\"].merge(full_data[\"question_data\"], on=[\"pid\",\"run\"])\n",
    "\n",
    "time_format = '%Y-%m-%d %H:%M:%S.%f'\n",
    "finished_df = individual_variables[individual_variables[\"endhit\"].apply(lambda endhit: isinstance(endhit, str))].reset_index()\n",
    "finished_df[\"time_diff\"] = finished_df.apply(lambda row: ((datetime.strptime(row[\"endhit\"], time_format) - datetime.strptime(row[\"beginhit\"], time_format)).seconds % 3600 )/ 60.0, axis=1)\n",
    "individual_variables = individual_variables.merge(finished_df[[\"time_diff\", \"pid\", \"run\"]], how=\"left\", on=[\"pid\", \"run\"])\n",
    "\n",
    "# check saved cost makes sense\n",
    "if (COST is not None) and (DEPTH is not None):\n",
    "    if isinstance(COST, dict):\n",
    "        assert(np.all(individual_variables.apply(lambda row: row[\"COST\"] == COST[row[\"codeversion\"]][int(row[\"cond\"])],axis=1)))\n",
    "    else:\n",
    "        unique_costs = np.unique(individual_variables[\"COST\"])\n",
    "        assert(len(unique_costs) == 1)\n",
    "        assert(unique_costs[0] == COST)\n",
    "    if DEPTH:\n",
    "        if isinstance(DEPTH, dict):\n",
    "            assert(np.all(individual_variables.apply(lambda row: row[\"DEPTH\"] == DEPTH[row[\"codeversion\"]][int(row[\"cond\"])],axis=1)))\n",
    "        else:\n",
    "            unique_costs = np.unique(individual_variables[\"DEPTH\"])\n",
    "            assert(len(unique_costs) == 1)\n",
    "            assert(unique_costs[0] == DEPTH)\n",
    "    print(finished_df.groupby([\"DEPTH\", \"COST\"]).mean())\n",
    "else:\n",
    "    print(finished_df.groupby([\"cond\"]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "survey_texts = preprocess_survey_text(full_data[\"survey-text\"])\n",
    "\n",
    "if old_experiment:\n",
    "    demographics, demo_text = get_old_demographics(survey_texts, experiment_specific_gender=experiment_specific_mapping, manual_age_mapping=manual_age_mapping)\n",
    "else:\n",
    "    html_survey = full_data[\"survey-html-form\"]\n",
    "    if len(html_survey_names) > 0:\n",
    "        if \"name\" not in html_survey:\n",
    "            html_survey[\"name\"] = np.nan\n",
    "\n",
    "        html_survey[\"name\"] = html_survey.apply(\n",
    "            lambda row: get_mouselab_quiz_name(row, html_survey_names[row[\"run\"]]) if not isinstance(row[\"name\"], str) else row[\"name\"],\n",
    "            axis=1)\n",
    "        demographics, demo_text = process_html_demographics(html_survey[html_survey[\"name\"] == \"demographics\"])\n",
    "        full_data[\"survey-multi-choice\"] = pd.concat([full_data[\"survey-multi-choice\"], html_survey[html_survey[\"name\"] != \"demographics\"]])\n",
    "    else:\n",
    "        demographics, demo_text = process_html_demographics(full_data[\"survey-html-form\"])\n",
    "    \n",
    "print(demo_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mouselab_datas = preprocess_mouselab_data(full_data[\"mouselab-mdp\"],trials_per_block,ground_truths)\n",
    "\n",
    "mouselab_datas = mouselab_datas.merge(individual_variables, how=\"left\", on=[\"pid\", \"run\"])\n",
    "\n",
    "# path may contain a bunch of 0s at the start due to miscoding\n",
    "mouselab_datas[\"path\"] = mouselab_datas[\"path\"].apply(lambda path : eval(path)[-3:])\n",
    "\n",
    "node_classification = {key : [str(node) for node in val] for key, val in node_classification.items()}\n",
    "mouselab_datas = add_click_count_columns(mouselab_datas, node_classification)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#TODO would be nice to refactor this out and import it\n",
    "def expand_range_dictionary(input_dictionary):\n",
    "    trial_to_block = {}\n",
    "    for block, trial_range in input_dictionary.items():\n",
    "        if isinstance(trial_range, str):\n",
    "            for trial_index in eval(trial_range):\n",
    "                trial_to_block[trial_index] = block\n",
    "        else:\n",
    "            trial_to_block[block] = expand_range_dictionary(trial_range)\n",
    "    return trial_to_block\n",
    "\n",
    "if ranges_to_extract:\n",
    "    trial_to_block = expand_range_dictionary(ranges_to_extract)\n",
    "\n",
    "    mouselab_datas[\"block\"] = mouselab_datas.apply(lambda row: trial_to_block[row[\"run\"]][row[\"trial_index\"]] if row[\"run\"] in trial_to_block else trial_to_block[row[\"trial_index\"]], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "questionnaires = full_data[\"survey-multi-choice\"]\n",
    "\n",
    "if \"name\" not in questionnaires:\n",
    "    questionnaires[\"name\"] = np.nan\n",
    "\n",
    "questionnaires[\"name\"] = questionnaires.apply(\n",
    "    lambda row: get_mouselab_quiz_name(row, mouselab_mapping) if not isinstance(row[\"name\"], str) else row[\"name\"],\n",
    "    axis=1)\n",
    "\n",
    "mouselab_questionnaires = questionnaires[questionnaires[\"name\"].isin(mouselab_mapping.values())].reset_index()\n",
    "questionnaires = questionnaires[~questionnaires[\"name\"].isin(mouselab_mapping.values())].reset_index()\n",
    "\n",
    "mouselab_questionnaires[\"name\"] = mouselab_questionnaires.apply(lambda row: get_mouselab_quiz_name(row, mouselab_mapping) if not isinstance(row[\"name\"], str) else row[\"name\"],axis=1)\n",
    "mouselab_questionnaires = score_mouselab_questionnaires(mouselab_questionnaires, mouselab_quiz_solutions, mouselab_column_identifier)\n",
    "mouselab_quiz = mouselab_questionnaires.drop_duplicates([\"pid\",\"question_id\"], keep=\"last\")\n",
    "\n",
    "pivoted_mouselab_quiz = mouselab_quiz.pivot_table(values=\"score\", index=[\"pid\",\"run\"], columns=\"question_id\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if len(questionnaires)>0:\n",
    "    raise NotImplementedError"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "quiz_passers = get_quiz_passer_ids(mouselab_questionnaires, max_attempts=max_attempts, passing_score=passing_score, identifying_columns = [\"pid\", \"run\"])\n",
    "passed_all_quizzes = list(set.intersection(*map(set,quiz_passers.values())))\n",
    "print(len(passed_all_quizzes))\n",
    "pivoted_mouselab_quiz[\"passed_quizzes\"] = 0\n",
    "pivoted_mouselab_quiz.loc[passed_all_quizzes, \"passed_quizzes\"] = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "quiz_and_demo = pivoted_mouselab_quiz.join(demographics)\n",
    "quiz_and_demo = quiz_and_demo.merge(individual_variables, how=\"left\", on=[\"pid\", \"run\"])\n",
    "\n",
    "quiz_and_demo_subselection = quiz_and_demo[quiz_and_demo.apply(lambda row: (row[\"pid\"], row[\"run\"]) in \\\n",
    "                                 passed_all_quizzes, axis=1)]\n",
    "\n",
    "gender_values, gender_counts = np.unique(quiz_and_demo_subselection[\"gender\"].values, return_counts = True)\n",
    "print(get_demo_string(list(map(int, quiz_and_demo_subselection[\"age\"].values)), gender_counts, gender_values))\n",
    "\n",
    "\n",
    "if len(questionnaires)>0:\n",
    "    scored_questionnaire_df.to_csv(processed_data_path.joinpath(\"questionnaires.csv\"))\n",
    "quiz_and_demo[quiz_and_demo.apply(lambda row: (row[\"pid\"], row[\"run\"]) in \\\n",
    "                                 passed_all_quizzes, axis=1)].to_csv(processed_data_path.joinpath(\"quiz-and-demo.csv\"))\n",
    "mouselab_datas[mouselab_datas.apply(lambda row: (row[\"pid\"], row[\"run\"]) in \\\n",
    "                                 passed_all_quizzes, axis=1)].to_csv(processed_data_path.joinpath(\"mouselab-mdp.csv\"))\n",
    "survey_texts[survey_texts.apply(lambda row: (row[\"pid\"], row[\"run\"]) in \\\n",
    "                                 passed_all_quizzes, axis=1)].to_csv(processed_data_path.joinpath(\"survey-text.csv\"))\n",
    "individual_variables[individual_variables.apply(lambda row: (row[\"pid\"], row[\"run\"]) in \\\n",
    "                                 passed_all_quizzes, axis=1)].to_csv(processed_data_path.joinpath(\"individual-variables.csv\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "median_info = finished_df[finished_df.apply(lambda row: (row[\"pid\"], row[\"run\"]) in \\\n",
    "                                 passed_all_quizzes, axis=1)].median()\n",
    "print(f\"median time: {median_info['time_diff']:.2f}, median bonus: {median_info['final_bonus']:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "irl-project",
   "language": "python",
   "name": "irl-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}